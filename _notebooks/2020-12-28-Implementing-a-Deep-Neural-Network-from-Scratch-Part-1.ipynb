{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-12-28-Implementing-a-Deep-Neural-Network-from-Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a83a32c32065476baa74407ecdbaa1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb4d22992d364888905835f77f156233",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90da5570ee014c81ae1536f4ccb6155c",
              "IPY_MODEL_38a8ea4f96294d95943392ce82d45934",
              "IPY_MODEL_3184fed9e42d42f882ac3e89e4138709"
            ]
          }
        },
        "bb4d22992d364888905835f77f156233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90da5570ee014c81ae1536f4ccb6155c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "state": {
            "_view_name": "FloatSliderView",
            "style": "IPY_MODEL_e3d9b918ec7b4effadc638db7d33a062",
            "_dom_classes": [],
            "description": "a",
            "step": 0.5,
            "_model_name": "FloatSliderModel",
            "orientation": "horizontal",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": -2,
            "continuous_update": true,
            "readout_format": ".2f",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70d3577a4cb84998b1fc7fdd357cf86b"
          }
        },
        "38a8ea4f96294d95943392ce82d45934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "state": {
            "_view_name": "FloatSliderView",
            "style": "IPY_MODEL_b9268c3c756f4e94a5ba621bd86ee833",
            "_dom_classes": [],
            "description": "b",
            "step": 0.25,
            "_model_name": "FloatSliderModel",
            "orientation": "horizontal",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": -2,
            "continuous_update": true,
            "readout_format": ".2f",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb192dc4ecc846269beb5b38b2f659dd"
          }
        },
        "3184fed9e42d42f882ac3e89e4138709": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": [],
                  "needs_background": "light"
                },
                "image/png": "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\n",
                "text/plain": "<Figure size 432x288 with 1 Axes>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_85e8f491288148cf956c8e82b1b2c87b",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "e3d9b918ec7b4effadc638db7d33a062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70d3577a4cb84998b1fc7fdd357cf86b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9268c3c756f4e94a5ba621bd86ee833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb192dc4ecc846269beb5b38b2f659dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85e8f491288148cf956c8e82b1b2c87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": "350px",
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "# Implementing a Deep Neural Network from Scratch - Part 1\n",
        "> In this series we'll build a Neural Network from the ground up, covering basic concepts along the way. In Part 1 we will cover some fundamentals, create a simple baseline algorithm and build our first model.\n",
        "\n",
        "- toc: true\n",
        "- badges: false\n",
        "- comments: true\n",
        "- categories: [machine-learning]\n",
        "- image: images/nn-from-scratch-part-1.png\n",
        "- sticky_rank: 1\n",
        "- keywords: machine learning, ml, deep neural network, neural network, convolutional neural network, beginner concepts, fastai, fast.ai, pytorch"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9zzkgKSnGXB"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "One of the best ways to truly understand an algorithm, an API, or really any practical concept, is to build it yourself. In this blog post, we will implement a Deep Neural Network Multi-Label Text Classifier from scratch using Python, debunking the impression that modern Machine Learning is an obscure black box full of mind-bendingly complicated math. \n",
        "\n",
        "Our goal will be to create a Neural Network that can distinguish all 10 handwritten digits (using the industry standard [MNIST](http://yann.lecun.com/exdb/mnist/) dataset). This is also known as a Multi-Label Classifier (a single-label classifier only has two labels, such as cat or dog, hotdog or not hotdog, etc). I'll be basing this post on Lesson 4 of the excellent [fast.ai tutorial](https://course.fast.ai/) on Deep Learning, where Jeremy Howard shows how to distinguish whether a digit is a 3 or a 7 (a single label classifier). We'll need to change some things to make it work for all ten digits (0-9).\n",
        "\n",
        "To truly test your understanding, I encourage you to try this yourself with a different type of dataset.\n",
        "\n",
        "## Terminology\n",
        "\n",
        "Most concepts that appear complicated are actually quite simple once you look at its building blocks. Complexity often arises from an aggregation of simplicity, and with Neural Networks this is exactly the case. The foundation of a Neural Network is collection of neurons. A neuron takes in a value, does a mathematical operation and outputs another value. That's it. The reason Neural Networks are powerful, is in the _how_: how the neurons work together, and how the output values in each neuron are calculated.\n",
        "\n",
        "If you remember from high school math, one of the simplest equations is that of a linear function (i.e. the equation of a straight line): \n",
        "\n",
        "$y = \\textbf{a}x + \\textbf{b}$\n",
        "\n",
        "$\\textbf{a}$ and $\\textbf{b}$ are constants (i.e. numbers like 2 or 3). For any value $x$ that we feed in, $\\textbf{a}$ influences that slope (or gradient) of the line, $\\textbf{b}$ determines the offset of the line along the $y$ axis.\n",
        "\n",
        "![](images/2xp1.png)\n",
        "\n",
        "[Here is an interactive example](https://www.mathsisfun.com/data/straight_line_graph.html) where you can see how $x$ is affected by changes in $\\textbf{a}$ and $\\textbf{b}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVF72WCU04CC"
      },
      "source": [
        "Guess what: each neuron in a Neural Network is a linear function almost identical to the above. The main differences lie in how we call each parameter and how the values of the function are affected once we start connecting neurons together. This is why we refer to the neurons as \"**linear units**\". From here on out, we'll call them linear units or LU(s).\n",
        "\n",
        "The function for a linear unit is equivalent to the one we saw earlier:\n",
        "\n",
        "$y = wx + b$\n",
        "\n",
        "Almost identical right? The only difference is that $a$ turned into a $w$. This is because at the heart of a linear unit, the input is affected by a **weight** $w$ and a **bias** $b$. Here's another way to look at it, visually:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "XpjLoqSUxnkF",
        "outputId": "2c06b989-a930-4ba2-eb7c-daad894be233"
      },
      "source": [
        "#hide_input\n",
        "gv('''\n",
        "bias->\"neuron aka L.U.\"->output\n",
        "input->weight->\"neuron aka L.U.\"\n",
        "''')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fb5ed2be470>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"464pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 464.37 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 460.3691,-94 460.3691,4 -4,4\"/>\n<!-- bias -->\n<g id=\"node1\" class=\"node\">\n<title>bias</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.4913\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"133.4913\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bias</text>\n</g>\n<!-- neuron aka L.U. -->\n<g id=\"node2\" class=\"node\">\n<title>neuron aka L.U.</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"278.0317\" cy=\"-45\" rx=\"72.2875\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"278.0317\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">neuron aka L.U.</text>\n</g>\n<!-- bias&#45;&gt;neuron aka L.U. -->\n<g id=\"edge1\" class=\"edge\">\n<title>bias&#45;&gt;neuron aka L.U.</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M159.6665,-67.1105C173.8753,-64.4563 192.1638,-61.04 210.0954,-57.6904\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"210.8051,-61.1185 219.9924,-55.8417 209.5197,-54.2375 210.8051,-61.1185\"/>\n</g>\n<!-- output -->\n<g id=\"node3\" class=\"node\">\n<title>output</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"421.2722\" cy=\"-45\" rx=\"35.194\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"421.2722\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n</g>\n<!-- neuron aka L.U.&#45;&gt;output -->\n<g id=\"edge2\" class=\"edge\">\n<title>neuron aka L.U.&#45;&gt;output</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M350.4912,-45C359.0795,-45 367.6516,-45 375.7136,-45\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"375.9765,-48.5001 385.9764,-45 375.9764,-41.5001 375.9765,-48.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node4\" class=\"node\">\n<title>input</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"30.5473\" cy=\"-18\" rx=\"30.5947\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"30.5473\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- weight -->\n<g id=\"node5\" class=\"node\">\n<title>weight</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.4913\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"133.4913\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">weight</text>\n</g>\n<!-- input&#45;&gt;weight -->\n<g id=\"edge3\" class=\"edge\">\n<title>input&#45;&gt;weight</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M61.1552,-18C69.2489,-18 78.1712,-18 86.9042,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.0081,-21.5001 97.0081,-18 87.0081,-14.5001 87.0081,-21.5001\"/>\n</g>\n<!-- weight&#45;&gt;neuron aka L.U. -->\n<g id=\"edge4\" class=\"edge\">\n<title>weight&#45;&gt;neuron aka L.U.</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M167.7454,-24.3986C180.4294,-26.768 195.2974,-29.5453 209.9363,-32.2798\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.5319,-35.7648 220.0046,-34.1606 210.8173,-28.8838 209.5319,-35.7648\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2F0-fMg3LJV"
      },
      "source": [
        "Why so much fuss about Neural Networks? Well, the power of neural networks is that theoretically they are able to approximate any function, at any level of accuracy. This is called the [Universal Approximation Theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem). If you're interested in diving deeper into how this works, I recommend reading [this post](http://neuralnetworksanddeeplearning.com/chap4.html) that visually (and interactively) shows how Neural Networks are able to approximate any function. \n",
        "\n",
        "We've made some bold claims: something that can replicate any known function with _any_ level of theoretical accuracy...and just thanks to a simple linear function? Well, yes! And no. As mentioned ealier, the real magic of a Neural Network lies not in how each neuron (linear unit) behaves independently, but how they behave as a whole. We'll see how this works as we build our Neural Network.\n",
        "\n",
        "By the way, if you need a little more context on the topics covered above, I highly recommend the [Kaggle course](https://www.kaggle.com/ryanholbrook/a-single-neuron) on the subject."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ObvXMp1DmJi"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "Now that we've understood what lies at the foundation of a Neural Network, we can start implementing it. Let's begin by importing and taking a look at the data we will be using. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S6kFh_pl2Qdw",
        "outputId": "69c4e0da-7d35-45eb-9c83-fa3392744fbb"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGEix4MEF3Qr"
      },
      "source": [
        "Our data is made up of two directories: `training/` and `testing/`. In each folder, the PNGs of the digits (0 to 9) are grouped into folders themselves. The training dataset has a total of 60,000 reference images and the testing a total of 10,000 (so roughly a 15-16% validation split). \n",
        "\n",
        "```\n",
        "mnist_png/ (70,000 files) \n",
        "├── training/ (60,000 files)\n",
        "│   ├── 0/\n",
        "│   │   ├── 44897.png\n",
        "│   │   ├── 28230.png\n",
        "│   │   └── ...\n",
        "│   ├── 1/\n",
        "│   │   ├── 44680.png\n",
        "│   │   ├── 37659.png\n",
        "│   │   └── ...\n",
        "│   ├── ...\n",
        "│   └── 9/\n",
        "└── testing/ (10,000 files)\n",
        "    └── ... (same structure as training/)\n",
        "```\n",
        "\n",
        "The reason we need the two folders is that we'll \"learn\" how to recognize the digits using the larger training set, and measure our performance accuracy against the testing dataset. If we were to test our performance on the dataset we learn from, we would always inevitably get 100% accuracy as the model learns to distinguish individual files. This sounds great, but the reality is it would perform terribly in a production environment when it encounters images of digits it has never seen before.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F82Pg4cZFuzw"
      },
      "source": [
        "# Importing the paths of our training and testing images\n",
        "training = { f'{num}' : (path/f'training/{num}').ls().sorted() for num in range(10) }\n",
        "testing = { f'{num}' : (path/f'testing/{num}').ls().sorted() for num in range(10) }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "mwzC9y_2VgNn",
        "outputId": "7458bf11-1e01-4cef-ab2e-8b42e096f2d9"
      },
      "source": [
        "# Let's take a look at a random 0\n",
        "zero_path = training['0'][0]\n",
        "zero = Image.open(zero_path)\n",
        "zero"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FB5EFCD7128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Sro8fDFkh4"
      },
      "source": [
        "In order to work with our images, we need to convert this image into a numerical representation. Usually, a 2D image is represented by a matrix array (i.e. a Python list, a Javascript array, etc). There are a couple Python libraries that have extended the standard list object to be a bit more flexible (e.g. a numpy array). The object we'll be using is a PyTorch tensor. PyTorch is a popular Deep Learning Python Library. While _tensor_ may sound like a fancy name, it's nothing more than an array that has a couple extra features. From here on out, when we refer to a tensor, we mean an array. Let's convert our zero to a tensor and visualize it numerically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensor(zero)"
      ]
    },
    {
      "source": [
        "![](images/zero_tensor_1.png)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcxoxlBDW2Da"
      },
      "source": [
        "Without being Neo from the matrix, you can make out the zero drawn as if in ascii text. This is because each value of the array represents a pixel value, in the case of grey scale, from 0 to 255. Any place there is no color data, we have 0s.\n",
        "\n",
        "Given that this is a 2D matrix, we can access specific parts of the tensor using notation such as `zero[5:10,5:10]` which will output the rows from index 5 (included) to 10 (excluded) and the same for the columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3xXMZ2lXfm-",
        "outputId": "34d55861-78ec-4947-9ebb-d4bf04997633"
      },
      "source": [
        "z_t = tensor(zero)\n",
        "z_t[6:10,10:15] # This will output rows 7-10 (index 6-9) and columns 11-15 (index 10-14)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  54, 227],\n",
              "        [  0,  10,  60, 224, 252],\n",
              "        [  0, 163, 252, 252, 252],\n",
              "        [ 51, 238, 253, 253, 190]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAN7A3LyYEbW"
      },
      "source": [
        "Let's visualize the tensor a little better:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(z_t)\n",
        "df.style.set_properties(**{'font-size':'5pt'}).background_gradient('Greys')"
      ]
    },
    {
      "source": [
        "![](images/zero_tensor_2.png)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kskt9HeYZE4"
      },
      "source": [
        "This is the anatomy of our digits: 28 rows long by 28 columns wide, making a total of 784 pixels each. Each pixel is represented by a value from 0-255.\n",
        "\n",
        "Before we start, let's first ponder on how we could, without knowing _anything_ but the structure of the data, teach a computer how to differentiate between the digits. We'll do that in the next section, and use it as a baseline to measure our Neural Network against."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yh6GgN-FSEq"
      },
      "source": [
        "## Establishing a Baseline\n",
        "\n",
        "We'll begin our implementation by implementing something that _isn't_ a neural network. It sounds counter-intuitive, but in order to get a good understanding of the performance of our model, we should always have a simple baseline with which to compare it against. Usually a good baseline is something simple, easy to create, and easy to understand. Seeing as how we're building everything from scratch, we may as well build our baseline from scratch as well. \n",
        "\n",
        "In our case, there are several ways to approach this problem without knowing a single thing about machine learning. One approach could be just comparing the pixel similarity of the digits. This can be done by counting the average number of non-0 pixels for each image, or measuring the average pixel value of each image, or the average sum of pixel values, etc). Let's pick comparing average pixel values as the \"algorithm\" for our baseline algorithm. \n",
        "\n",
        "### Average Pixel Value\n",
        "\n",
        "To calculate average pixel value, we will take the average value of each pixel coordinate across every respective digit's training image's tensor. For example, we take all the '5' image tensors, we look at the first coordinate (1,1) in each tensor and we take the average value. We repeat the process for each coordinate until we create a map of average values across the 28x28 grid of pixels. An easy way to do this is to create a tensor that \"houses\" all of the individual image tensors. This will take our tensor from 2 dimensions, to 3 (also called a rank-3 tensor). This allows us to work with all of the tensors as a single stack, and conduct mathematical operations such as `tensor.mean()` without looping. We'll see later why that's not just convenient, but very important for performance.\n",
        "\n",
        "Going into the third dimenion sounds complicated, but all we're really doing is nesting each of the digit's various PNGs' tensors into a larger tensor. We do this with PyTorch's `stack` method which does just that. While we're at it, we'll also normalize our pixel values to be from 0 to 1 by dividing by 255 after converting them to float.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEwdPXTCgjp8",
        "outputId": "9448c699-7c08-4d8b-862d-dd91d0a4b0f8"
      },
      "source": [
        "# Generate training tensors for each digit in the training list:\n",
        "# For each digit from 0 to 9, we create a stacked tensor \n",
        "# containing the tensors for each PNG image, after converting\n",
        "# each pixel value to a float and dividing it by 255.\n",
        "\n",
        "training_tensors = [\n",
        "      torch.stack([\n",
        "            tensor(Image.open(digit)).float()/255 for digit in training[f'{num}']\n",
        "          ]) for num in range(10)\n",
        "      ]\n",
        "\n",
        "# Preview the shape of the stacked tensors of the \"zero\" digit PNGs\n",
        "training_tensors[0].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5923, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO1Fq_Qzgay6"
      },
      "source": [
        "We now have a list of stacked tensors (i.e. a list of stacked tensors of each digit). Each stacked tensor has $n$ tensors for each PNG image (rows), and each row contains a 28x28 tensor representing that PNG's pixel values normalized from 0 to 1.\n",
        "\n",
        "We can check this by inspecting the first item in our list of `training_tensors`: the stacked tensor of \"zero\" PNGs has _shape_ `torch.Size([5923, 28, 28])`: because it has 5923 rows (equal to the number of training images), each containing a 28x28 tensor (equal to the pixels in each image). If you're having trouble picturing a 3D tensor in your head, think of it like an array of array of arrays (or a list of list of lists in Python). \n",
        "\n",
        "## Calculating Average Pixel values\n",
        "\n",
        "The convenient part of having used tensors, is that now we can quickly calculate the mean across a desired dimension (in our case: flatten each stack into a single 28x28 tensor containing the average values of each pixel in the stack). \n",
        ">Tip: Think of it like printing out all the PNG images for a specific digit and stacking each page one on top of the other. That's exactly what we did with out stacked tensor. And now, with special X-Ray vision, we are going to reduce the stack to a single page by taking the average value for each printed pixel across the stack of pages. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "XDfRNbNTdDmA",
        "outputId": "f2e51b78-d3dc-4d4a-d6a6-eaff1d1b4805"
      },
      "source": [
        "# Flattening the stacks to calculate the means\n",
        "training_means = [t.mean(0) for t in training_tensors]\n",
        "\n",
        "# Let's display the \"mean\" tensor of the digits\n",
        "f, axarr = plt.subplots(2,5)\n",
        "digit = 0\n",
        "for i in range(2):\n",
        "  for j in range(5):\n",
        "    axarr[i,j].imshow(training_means[digit], cmap=\"gray\")\n",
        "    digit += 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DovW3_BxnqHF"
      },
      "source": [
        "Pretty cool right? That is the \"average\" pixel value for each digit, representing in a way the _ideal_ digit according to our baseline algorithm that will compare the validation digits against this mean. The value we will be measuring is called _distance_. Our validation digits will of course be very different from these reference means, but hopefully the pixel values will be nearest in _distance_ to the mean pixel value of the correct digit! Let's see if that's the case...\n",
        "\n",
        "### Measuring Distance\n",
        "\n",
        "In order to measure the distance between our reference means and the validation digits, we need to subtract them. However we can't simply subtract them, as that would create negative numbers and our pixel values go from 0 to 1. \n",
        "\n",
        "To avoid dealing with negative numbers, there are two common measures of distance that get rid of negative numbers altogether:\n",
        "-  **mean absolute difference** (aka L1 Norm)\n",
        "-  **root mean squared error** (aka RMSE or L2 Norm). \n",
        "\n",
        "If these sound confusing you'll see how simple they are in just a second.\n",
        "\n",
        "**Mean Absolute Difference**: $mean( abs( a - b ) )$. For each prediction, we subtract our prediction from the actual value, turn that difference into a positive number (i.e. remove the negative sign if there is one) and then average all the these differences together together. \n",
        "\n",
        "**Root Mean Squared Error / RMSE**: $\\sqrt[]{mean((a-b)^2)}$. For each prediction, we subtract our prediction from the actual value, square the result (so as to turn it into a positive number) and then take the square root, so as to \"cancel out\" the squaring. \n",
        "\n",
        "In code, they are even easier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBtdqucBrWLN"
      },
      "source": [
        "def mean_absolute_difference(a, b):\n",
        "    return (a - b).abs().mean()\n",
        "\n",
        "def rmse(a, b):\n",
        "    return ((a - b)**2).mean().sqrt()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqAKH09fr7sm"
      },
      "source": [
        "Now that we've defined them, let's pick a random image from the validation set (e.g. the first image in the '5' in the testing list) and calculate its distance from the training set's reference mean. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M6KafJ7eLGG",
        "outputId": "90dc1060-7c20-4a21-a3b1-5e2e0f0ad492"
      },
      "source": [
        "val_5 = tensor(Image.open(testing['5'][0])).float()/255\n",
        "# val_5.shape => torch.Size([28, 28])\n",
        "\n",
        "# Let's compare it to the reference mean of 5\n",
        "mean_absolute_difference(training_means[5], val_5), rmse(training_means[5], val_5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1683), tensor(0.2988))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVx3N7jDI4PX"
      },
      "source": [
        "# Now let's compare it to all the other means\n",
        "mad_all = [mean_absolute_difference(training_means[num], val_5) for num in range(10)]\n",
        "rmse_all = [rmse(training_means[num], val_5) for num in range(10)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "5KF5jEdvsYlZ",
        "outputId": "0e478eac-cb9b-4b07-f940-5fa4de964008"
      },
      "source": [
        "#hide_input\n",
        "# Plot results for a visual inspection\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Mean Abs. Diff. for a random '5'\")\n",
        "plt.axhline(mad_all[5], color='red', linewidth=1)\n",
        "plt.xticks(range(0, 10))\n",
        "plt.xlabel('Digits')\n",
        "plt.bar(range(len(mad_all)), mad_all, align='center')    \n",
        "plt.plot()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"MRSE for a Random '5'\")\n",
        "plt.axhline(rmse_all[5], color='red', linewidth=1)\n",
        "plt.xticks(range(0, 10))\n",
        "plt.xlabel('Digits')\n",
        "plt.bar(range(len(rmse_all)), rmse_all, align='center')    \n",
        "plt.plot()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7gcVZ3u8e9rAhG5Bth4NBASJKgBPEE2F0eNHK7BS8AjaEAxOAwZjuQMc9AZ4QFhRHFEHXGcYRSUu3ITRKKCCEq8B7ID4ZIwSBIiJIIECDfBQOB3/lirQ6XpvXf1vnX13u/nefrZXVVrVa3qXdW/qtWr1lJEYGZmVjWvaXUBzMzMGnGAMjOzSnKAMjOzSnKAMjOzSnKAMjOzSnKAMjOzSnKA6oWkkLRjC7Y7XtKzkkbl6ddL+pWkZyT9m5ILJa2WdFsv6yqdth1JOlrSb1pdDmu94X6sF42E435IA5Sk5ZJekLR13fw7ciCYMJTlKWx/oqSXJX1ziLZ3tKSXcgB6VtID+aTaqZYmIh6MiE0i4qU8axbwGLBZRHwKeBdwALBtROzZyyabSWvdkDRB0vLC9FxJfy38H+8rLDta0kWtKOdQKXs+S7oop3tW0hOSbpL0lkL6DfNF14qcZrmkr9dt5/nC5/yspP/splgtPdbrjonHJP1A0huGuhwDqZXHfSvuoB4AjqhNSNoVeF0LylH0cWA18BFJY4Zom7+PiE2AzYH9geeBBZJ26Sb99sDieOXJ6u2B5RHxlxLbaibteiSNbjZPL+uTpOF05z47X0hsEhFvbnVhWqDs+fzlfLyPA1YC5xeWnQx0AnsCmwL7ALfX5f9A4XPeJCJmd1OeKhzrs/O+7ghsAnx1gNZbJUNy3Lfii+JSUkComQlcUkwgaYykr0p6UNKfJX1L0kZ52VhJP5a0Kt/G/1jStoW8cyV9XtJvc3XYz+qv8Oq2pVyeU4EXgQ80SPZeScvyFdFXal+wknaU9EtJT+VlVzb7YUTESxGxNCI+CfwS+Je87gn5KnR0viKZCfxzvmL5e+A7wDvy9Od62L9jGqWVdKykJfmKdo6kNxbyhKTjJd0P3N/Ner8v6ZG877+StHMPZZgr6UxJvwWeA3aQ9AlJ9+b/0bK8T7X0++Sr6U9JelTSw5I+UVi+VS7z00rVOG+q297fSJqfyzZf0t/UleULkn6XP48f5fV9L69vvlp0J9+mej2fiyLieeAqYEph9h7AtRHxp0iWR0S36+hOFY71un19EvhhcV993DcpIobsBSwn3S3cB7wVGAWsIF31BDAhpzsbmANsSbqi+hHwr3nZVsCHSFdpmwLfB35Y2MZcYCmwE7BRnv5SD2V6N7AGGAv8B/CjuuUB3JLLMh74A/B3ednlwCmkQP9a4F0lP4ejgd80mP+3wJ/z+wl526Pz9EXAF3pbR5ntAfuSqgvfDozJ+/2run2+Ke/zRt2s82/z5z8G+DqwsIftzwUeBHYGRgMbAO8jnWAC3kMKXG/P6fcB1gJn5LTvzcvH5uVXkL7kNgZ2IV2R/yYv25J0N3xU3tYReXqrQlmW5G1vDizO/9P9c/pLgAtLfq5zgVX5s/wtsM9Qnk+tflH+fF537Ob/2aXAnYX1nJqPj08CuwJqtJ02OtZr3w9bATcD1xWW+7hv5hhr0QF9KvCvwLR8cIyuHdD5H/cX4E2FfO8AHuhmnVOA1XUf3qmF6U8CP+2hTN8hB7i8nReBbeoO4Gl16/t5fn8JcB6pvruZz2G9k6gwfxrwYn4/gcELUOeTqlxq05vk/a59oQSwbxP7s0XOs3kPB/QZvazjh8AJ+f0+pCrP0YXljwJ7k74EXwTeUlj2RV45UY8Cbqtb9++BowtlOaWw7N+AGwrTH6CHL6C69e7FK19cM4FnisftcH+VOZ8Lx+5fgSeBl0nVgm8rrGcUcDzpy24N8CdgZt12ns35a69jK3ysPwc8ldMtBMb7uO/bq1W/BVwKHEk6mOpv5TtId0cLJD0p6Ungp3k+kl4n6VxJf5T0NPArYAvl1m7ZI4X3z5EOyldRqjY8HPgeQET8nnQld2Rd0ocK7/8I1KoI/pkUUG+TtEjS3/a2470YBzzRz3WU8UbSfgAQEc8Cj+ft1zxUn6lG0ihJX5K0NP8PludF3Val1q9P0sGS5uVqlydJV4vF/I9HxNrCdO3/2EH6Aqz/nzTct8Ly4r79ufD++QbTDY+XehFxa0Q8ExFrIuJi0hfse8vkHWZ6Op9rvhoRW5AuvJ4H1v1uEama+5yIeCcpAJwJXCDprYX8h0bEFoXXt0uWrRXH+j9ExObA20g1M8WfIHzcN6ElASoi/ki6inov8IO6xY+RPqydCwfj5pF+dAT4FOng3isiNgOm5vnqQ1E+CGwG/FeuY36E9A+dWZduu8L78aQrPCLikYg4NiLeCPx9Xk9/mqR/EPh1P/KX9SdSNQwAkjYmVUesLKTpqZv7I4FDSFfPm5O+dKDn/8G69Sk1RLmG9OPx6/MX1/W95K9ZRaoGqf+f1Ky3b4XlKxl8Qd+Ow7bWy/lcn/ZB4ATg3/MFYv3y5yPiHFL11OQBKF4rjvW00oi7gS8A5yjxcd+kVramOoZ0a71ea5uIeBn4NnC2pG0AJI2TdFBOsikpgD0paUvg9H6UYSZwAanee0p+vRP4n0qtkWr+Salxxnakk+vKXK7D9UoDjdWkf9TLzRQgX6FNlPQfpFv8bhs8DKDLgU9ImpJPmi8Ct0bE8pL5NyVVxTxOutv9YpPb35BUPbAKWCvpYODAMhkjNbv/AfAv+W56MutfUFwP7CTpSKUGJh8hfdH9uMky9kjSFpIOkvTavJ2Pki6WfjqQ22kjDc/nRiLiJtIX6iwASf+YGwhslD/LmaRj7I4BKFerj/WLgdcD0/Fx37SWBahILde6uln8GdIPevPybfXNvFIl8HVS44fHgHn08YORNA7YD/h6vhOqvRbkdRb/+dcBC0j1yT/hlSayewC3SnqW1KjjhIhYlte/KP/zuvOOnO9pUv3wZsAe+aqrL/vzrKR3l0kbETcDnyVdzT1M+uF0RhObu4RUfbCS9GPrvGbKGhHPAP9A+sF3NekqdU4Tq5hNqo54hPT7xoWFdT8OvJ90p/04qRr2/RHxWDNlLGED0tVx7cfi/0uqhvrDAG+nLfRyPjfyFVKr1DGkaqx/I/0/HyP9HvWh2rmU/UjrPwd1bclytfpYfwH4d+CzPu6bp/yjl5mZWaUMpwcmzcxsGHGAMjOzSnKAMjOzSnKAMjOzShrQjkAH29Zbbx0TJkxodTFshFmwYMFjEdHR6nIMBZ9j1grdnWNtFaAmTJhAV1czLVnN+k9S/RP6w5bPMWuF7s4xV/GZmVklOUCZmVklOUCZVZykaZLuUxrT6KQe0n1IaXyjzsK8k3O++wrdhZm1hbb6DcpspMm99J9DGsZ8BTBf0pyIWFyXblNSP5G3FuZNJnXrszOpt+ubJe2U+3UzqzzfQZlV257AkohYlvt1u4LUu3a9zwNnkcZdqjkEuCIPi/AAqX/LPQe7wGYDxQHKrNrGsf4YQCtYf4wfJL0d2C4iftJs3px/lqQuSV2rVq0amFKbDQAHKLM2Juk1wNdIvVj3SUScFxGdEdHZ0TEiHveyNuHfoMyqbSXrD1K3LesPQrcpsAswVxLA/wDmSJpeIq9ZpfkOyqza5gOT8qCWG5IaPawbQyginoqIrSNiQkRMII1XND2PzTQHmCFpjKSJwCTgtqHfBbO+8R1UG5pwUv1PDd1b/qX3te02DSJiraTZwI3AKOCCiFgk6QygKyK6HfAup7uKNNDeWuD4VrXg8/FjfeEAZYOqmS8m8JdTIxFxPWlI7+K807pJu0/d9JnAmYNWOLNB5Co+MzOrJAcoMzOrJAcoMzOrpFIBqre+wCSdKGmxpLsk/VzS9oVlMyXdn18zC/N3l3R3Xuc3lNvImpmZQYkAVegL7GBgMnBE7uOr6A6gMyLeBlwNfDnn3RI4HdiL1MXK6ZLG5jzfBI4lNX2dBEzr996YmdmwUeYOqte+wCLiloh4Lk/OIz0QCHAQcFNEPBERq4GbgGmS3gBsFhHzIiKAS4BDB2B/zMxsmCjTzLxRf1579ZD+GOCGHvKOy68VDea/iqRZwCyA8ePHlyhu8/yMhplZ9QxoIwlJHwM6ga8M1DrdT5iZ2chU5g6qVH9ekvYHTgHeExFrCnn3qcs7N8/ftm5+2/UR5odQzazVhvP3UJk7qB77AgOQtBtwLqkPsEcLi24EDpQ0NjeOOBC4MSIeBp6WtHduvfdx4LoB2B8zMxsmer2DKtkX2FeATYDv59biD0bE9Ih4QtLnSUEO4IyIeCK//yRwEbAR6TerGzAzM8tK9cXXW19gEbF/D3kvAC5oML+LNEyAmVmluOFUNbgnCTMzqyQHKDMzqyQPt2FmVgHDuTVeXzlA2bDk3xDM2p+r+MzMrJKGzR2Ub4/NzIYX30GZVViJoW6Oy8PWLJT0m9pIA5ImSHo+z18o6VtDX3qz/hk2d1Bmw01hqJsDSB0qz5c0JyIWF5JdFhHfyumnA1/jlaFrlkbElKEss9lA8h2UWXWVGerm6cLkxkAMYfnMBpXvoMyqq9RQN5KOB04ENgT2LSyaKOkO4Gng1Ij4daONDMWQNjb8DEVLWd9BmbW5iDgnIt4EfAY4Nc9+GBgfEbuRgtdlkjbrJr+HtLFKcoAyq65SQ90UXEEemToi1kTE4/n9AmApsNMgldNsUDhAmVVXmaFuJhUm3wfcn+d35EYWSNoBmAQsG5JSmw0Q/wZlVlElh7qZnQcLfRFYDczM2acCZ0h6EXgZOK4w1I1ZW3CAMquwEkPdnNBNvmuAawa3dGaDywHKzCrLPcSMbKV+gyrxNPtUSbdLWivpsML8/1V4kn2hpL9KOjQvu0jSA4VlfqDQzMzW6fUOquTT7A8CRwOfLuaNiFuAKXk9WwJLgJ8VkvxTRFzdnx0wM7PhqUwV37qn2QEk1Z5mXxegImJ5XvZyD+s5DLghIp7rc2nNzGzEKFPF1+hp9nF92NYM4PK6eWdKukvS2ZLGNMokaZakLkldq1at6sNmzcysHQ3Jc1CS3gDsSmouW3My8BZgD2BL0lPwr+Kn3M3MRqYyAarZp9kb+TBwbUS8WJsREQ9Hsga4kFSVaGZmBpQLUL0+zV7CEdRV7+W7KiSJ1D3LPU2u08zMhrFeG0mUeZpd0h7AtcBY4AOSPhcRO0MaOI10B/bLulV/T1IHIGAhcNwA7ZOZDQI/k2RDrdSDuiWeZp9PqvprlHc5DRpVRMS+r05tZmaWuLNYMzOrpPbq6mjBApAaLlre7LrO6mPevuary9sfTW23xdtsKl9d3v5oarsDtE0zG1jtFaB23x26uhou6k/9eF9HhmxVnXwryjtSPqOGurkoMrPB5So+MzOrpPa6g7IRxa3GzEY230GZmVklOUCZmVklOUCZVVyJ8diOk3R3HlftN5ImF5adnPPdJ+mgoS25Wf84QJlVWGE8toOBycARxQCUXRYRu0bEFODLwNdy3smkrsl2BqYB/5XXZ9YWHKDMqm3deGwR8QJQG49tnYh4ujC5MRD5/SHAFRGxJiIeIA0Y6k6ZrW24FZ9ZtTUaj22v+kSSjgdOBDYEat2IjQPm1eV9VbdjkmYBswDGjx8/IIU2GwgOUGbDQEScA5wj6UjgVGBmE3nPA84D6JTCvbW0QW8the32NV9/NbXdPm7TAcqs2podj+0K4Jt9zOveWvqw3Vb01lLM226fUUPdXBQ5QJlV27rx2EjBZQZwZDGBpEkRcX+efB9Qez8HuEzS14A3ApOA24ak1NYWqv4wvAOUWYWVGY8NmC1pf+BFYDW5ei+nuwpYDKwFjo+Il1qyI2Z94ADVIlW/crHqKDEe2wk95D0TOHPwSmc2eEo1My/xoOBUSbdLWivpsLplL+UHCBdKmlOYP1HSrXmdV+bh5M3MzIASAarkg4IPAkcDlzVYxfMRMSW/phfmnwWcHRE7kqoljulD+c3MbJgqcwdV5kHB5RFxF/BymY1KEulZjavzrIuBQ0uX2szMhr0yAarRg4KvetivB6+V1CVpnqRaENoKeDIi1va2Tkmzcv6uVatWNbFZMzNrZ0PRSGL7iFgpaQfgF5LuBp4qm3m9hwg7O6OX5GZmNkyUCVDNP+xXEBEr899lkuYCuwHXAFtIGp3voppap5lZb9xStv2VqeJb96Bgbmk3g/QAYK8kjZU0Jr/fGngnsDgiArgFqLX4mwlc12zhzcxs+Oo1QOU7nNqDgvcCV9UeFJQ0HUDSHpJWAIcD50palLO/FeiSdCcpIH0pIhbnZZ8BTpS0hPSb1PkDuWNmZtbeSv0GVeJBwfmkarr6fL8Ddu1mnctw1/9mZtYNjwdlZmaV5ABlZmaV5ABlZmaV5ABlZmaV5ABlZmaV5ABlZmaV5ABlZmaV5ABlZmaV5ABlZmaV5ABlVmElRrM+UdJiSXdJ+rmk7QvLGo5mbdYuhmK4DTPrg8Jo1geQxkybL2lOoT9LgDuAzoh4TtL/Ab4MfCQvez4ipgxpoc0GkO+gzKqrzGjWt0TEc3lyHg36xDRrVw5QZtXV7GjWxwA3FKYbjWb9Kh612qrKVXxmw4CkjwGdwHsKs181mnVELK3P61Grrap8B2VWXaVGs5a0P3AKMD0i1tTmF0ezBuaSRrM2axsOUGbV1eto1pJ2A84lBadHC/MbjmY9ZCU3GwClAlSJpq5TJd0uaa2kwwrzp0j6vaRFuRnsRwrLLpL0QKEZrFsbmRWUGc0a+AqwCfD9uubkPY1mbdYWev0NqmRT1weBo4FP12V/Dvh4RNwv6Y3AAkk3RsSTefk/RcTV/d0Js+GqxGjW+3eTr9vRrM3aRZlGEuuaugJIqjV1XRegImJ5XvZyMWNE/KHw/k+SHgU6gCcxMzPrQZkqvmabujYkaU9gQ6DYiujMXPV3dq2+vEE+N4E1MxuBhqSRhKQ3AJcCn4iI2l3WycBbgD2ALYHPNMobEedFRGdEdHZ0dAxFcc3MrALKBKhSTV27I2kz4CfAKRExrzY/Ih6OZA1wIakq0czMDCgXoHpt6tqdnP5a4JL6xhD5rgpJAg4F7mmm4GZmNrz1GqDKNHWVtIekFcDhwLmSFuXsHwamAkc3aE7+PUl3A3cDWwNfGNA9MzOztlaqq6MSTV3n06CTyoj4LvDdbta5b1MlNTOzEcU9SZiZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJlVmKRpku6TtETSSQ2WnyhpcR5X7eeSti8smynp/vyaObQlN+s/ByizipI0CjgHOBiYDBwhaXJdsjuAzoh4G3A18OWcd0vgdGAv0lA2p0saO1RlNxsIDlBm1bUnsCQilkXEC8AVwCHFBBFxS0Q8lyfn8UqnzQcBN0XEExGxGrgJmDZE5TYbEA5QZtU1DnioML0iz+vOMcANfcxrVjmlhtsws2qT9DGgE3hPH/LOAmYBjB8/foBLZtZ3voMyq66VwHaF6W3zvPVI2h84BZgeEWuayQsQEedFRGdEdHZ0dAxIwc0GQqkAVaIl0VRJt0taK+mwumUNWxJJ2l3S3Xmd38hDv5vZK+YDkyRNlLQhMAOYU0wgaTfgXFJwerSw6EbgQEljc+OIA/M8s7bRa4Aq2ZLoQeBo4LK6vD21JPomcCwwKb/8A65ZQUSsBWaTAsu9wFURsUjSGZKm52RfATYBvi9poaQ5Oe8TwOdJQW4+cEaeZ9Y2yvwGta4lEYCkWkuixbUEEbE8L3u5Lu+6lkR5+U3ANElzgc0iYl6efwlwKK/8wGtmQERcD1xfN++0wvv9e8h7AXDB4JXObHCVqeLrT2ug7vKOy+/7sk4zMxsBKt9IQtIsSV2SulatWtXq4piZ2RApE6BKtwZqIu9KXnmgsMd1uoWRmdnIVCZA9dqSqAcNWxJFxMPA05L2zq33Pg5c14fym5nZMNVrgCrTkkjSHpJWAIcD50palPP21JLok8B3gCXAUtxAwszMCkr1JFGiJdF81q+yK6Zr2JIoIrqAXZoprJmZjRyVbyRhZmYjkwOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUWYVJmibpPklLJJ3UYPlUSbdLWivpsLplL0lamF9lh8gxq4xSvZmb2dCTNAo4BzgAWAHMlzQnIhYXkj0IHA18usEqno+IKYNeULNB4gBlVl17AksiYhmApCuAQ4B1ASoiludlL7eigGaDyVV8ZtU1DnioML0izyvrtZK6JM2TdGh3iSTNyum6Vq1a1deymg24UgGqRD34GElX5uW3SpqQ53+0UAe+UNLLkqbkZXPzOmvLthnIHTMzto+ITuBI4OuS3tQoUUScFxGdEdHZ0dExtCU060GvAapQD34wMBk4QtLkumTHAKsjYkfgbOAsgIj4XkRMyfXgRwEPRMTCQr6P1pZHxKMDsD9mw8lKYLvC9LZ5XikRsTL/XQbMBXYbyMKZDbYyd1Dr6sEj4gWgVg9edAhwcX5/NbCfJNWlOSLnNbNy5gOTJE2UtCEwAyjVGk/SWElj8vutgXdS+O3KrB2UCVBl6sHXpYmItcBTwFZ1aT4CXF4378JcvffZBgHNbETL59Js4EbgXuCqiFgk6QxJ0wEk7SFpBXA4cK6kRTn7W4EuSXcCtwBfqmv9Z1Z5Q9KKT9JewHMRcU9h9kcjYqWkTYFrSFWAlzTIOwuYBTB+/PihKK5ZZUTE9cD1dfNOK7yfT6r6q8/3O2DXQS+g2SAqcwdVph58XRpJo4HNgccLy2dQd/dUqB9/BriMVJX4Kv4B18xsZCoToMrUg88BZub3hwG/iIgAkPQa4MMUfn+SNDrXiyNpA+D9wD2YmZllvVbxRcRaSbV68FHABbV6cKArIuYA5wOXSloCPEEKYjVTgYdqDxtmY4Abc3AaBdwMfHtA9sjMzIaFUr9BlagH/yvpR9pGeecCe9fN+wuwe5NlNTOzEcQ9SZiZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJmZWSU5QJlVmKRpku6TtETSSQ2WT5V0u6S1kg6rWzZT0v35NbM+r1nVOUCZVZSkUcA5wMHAZOAISZPrkj0IHE0albqYd0vgdGAv0mjVp0saO9hlNhtIDlBm1bUnsCQilkXEC6RRqQ8pJoiI5RFxF/ByXd6DgJsi4omIWA3cBEwbikKbDZRSAapENcMYSVfm5bdKmpDnT5D0vKSF+fWtQp7dJd2d83xDkgZqp8yGiXHAQ4XpFXneYOc1q4ReA1TJaoZjgNURsSNwNnBWYdnSiJiSX8cV5n8TOBaYlF++ujNrAUmzJHVJ6lq1alWri2O2Tpk7qF6rGfL0xfn91cB+Pd0RSXoDsFlEzIuIAC4BDm269GbD20pgu8L0tnnegOaNiPMiojMiOjs6OvpUULPBUCZAlakqWJcmItYCTwFb5WUTJd0h6ZeS3l1Iv6KXdZqNdPOBSZImStoQmAHMKZn3RuBASWNz44gD8zyztjHYjSQeBsZHxG7AicBlkjZrZgWufrCRKl/szSYFlnuBqyJikaQzJE0HkLSHpBXA4cC5khblvE8AnycFufnAGXmeWdsYXSJNmaqCWpoVkkYDmwOP5+q7NQARsUDSUmCnnH7bXtZJzncecB5AZ2dnlCiv2bAREdcD19fNO63wfj7rn0vFdBcAFwxqAc0GUZk7qDLVDHOA2oOAhwG/iIiQ1JEbWSBpB1JjiGUR8TDwtKS9829VHweuG4D9MTOzYaLXO6iIWCupVs0wCrigVs0AdEXEHOB84FJJS4AnSEEMYCpwhqQXSc9pHFeoZvgkcBGwEXBDfpmZmQHlqvjKVDP8lVQHXp/vGuCabtbZBezSTGHNzGzkcE8SZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZmZWSQ5QZhUmaZqk+yQtkXRSg+VjJF2Zl98qaUKeP0HS85IW5te3hrrsZv1VasBCMxt6kkYB5wAHACuA+ZLmRMTiQrJjgNURsaOkGcBZwEfysqURMWVIC202gErdQfXjKu4ASQsk3Z3/7lvIMzevs3aFt81A7ZTZMLEnsCQilkXEC8AVwCF1aQ4BLs7vrwb2k6QhLKPZoOk1QBWu4g4GJgNHSJpcl2zdVRxwNukqDuAx4AMRsSswE7i0Lt9HI2JKfj3aj/0wG47GAQ8VplfkeQ3TRMRa4Clgq7xsoqQ7JP1S0ru724ikWZK6JHWtWrVq4Epv1k9l7qD6fBUXEXdExJ/y/EXARpLGDETBzaxHDwPjI2I34ETgMkmbNUoYEedFRGdEdHZ0dAxpIc16UiZA9fcqruZDwO0RsaYw78JcvffZ7qolfHVnI9hKYLvC9LZ5XsM0kkYDmwOPR8SaiHgcICIWAEuBnQa9xGYDaEha8UnamVTt9/eF2R/NVX/vzq+jGuX11Z2NYPOBSZImStoQmAHMqUszh1R9DnAY8IuICEkduXoeSTsAk4BlQ1RuswFRJkD1+SouT28LXAt8PCKW1jJExMr89xngMlJVoplluTZiNnAjcC9wVUQsknSGpOk52fnAVpKWkKryao2YpgJ3SVpIqnY/LiKeGNo9MOufMs3M113FkQLRDODIujS1q7jfs/5V3BbAT4CTIuK3tcQ5iG0REY9J2gB4P3Bzv/fGbJiJiOuB6+vmnVZ4/1fg8Ab5rgGuGfQCmg2iXu+g+nkVNxvYETitrjn5GOBGSXcBC0mB79sDuWNmZtbeSj2o24+ruC8AX+hmtbuXL6aZmY007urIzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyQHKzMwqyUoKJPYAAAd9SURBVAHKzMwqyQHKzMwqqVSAkjRN0n2Slkg6qcHyMZKuzMtvlTShsOzkPP8+SQeVXaeZJYNx/pm1g14DlKRRwDnAwcBk4AhJk+uSHQOsjogdgbOBs3LeycAMYGdgGvBfkkaVXKfZiDcY599Qld2sv8rcQe0JLImIZRHxAnAFcEhdmkOAi/P7q4H9JCnPvyIi1kTEA8CSvL4y6zSzwTn/zNqCIqLnBNJhwLSI+Ls8fRSwV0TMLqS5J6dZkaeXAnsB/wLMi4jv5vnnAzfkbD2us7DuWcCsPPlm4L4m93Fr4LEm8/QnX6vyuryDl3f7iOjo4/b6ZTDOv4i4um4brTrH+pN3pGyzP3nbqbwNz7HRfSzAkImI84Dz+ppfUldEdA5VvlbldXkHP+9w1apzrD95R8o2+5O33crbSJkqvpXAdoXpbfO8hmkkjQY2Bx7vIW+ZdZrZ4Jx/Zm2hTICaD0ySNFHShqQfXefUpZkDzMzvDwN+EanucA4wI7cymghMAm4ruU4zG5zzz6wt9FrFFxFrJc0GbgRGARdExCJJZwBdETEHOB+4VNIS4AnSSUROdxWwGFgLHB8RLwE0WufA7x7Q96qLPld5tCivyzv4eYfcYJ1/A2ykHD/tdsy2W3lfpddGEmZmZq3gniTMzKySHKDMzKyShm2A6mtXSpIukPRofrak2W1uJ+kWSYslLZJ0Qsl8r5V0m6Q7c77P9WHboyTdIenHTeZbLuluSQsldTWRbwtJV0v6b0n3SnpHyXxvztuqvZ6W9I8l8/6//PncI+lySa9torwn5HyLym7PeuZzrHQ+n2N9FRHD7kX6MXkpsAOwIXAnMLlk3qnA24F7+rDdNwBvz+83Bf5QZruAgE3y+w2AW4G9m9z2icBlwI+bzLcc2LoP+3ox8Hf5/YbAFn38Pz1Cekivt7TjgAeAjfL0VcDRJbezC3AP8DpSw6CbgR1beYy2+8vnWFP5fI718TVc76D63JVSRPyK1BKqaRHxcETcnt8/A9xL+qf3li8i4tk8uUF+lW69Imlb4H3Ad5oudB9I2pz0JXM+QES8EBFP9mFV+wFLI+KPJdOPBjbKz/q8DvhTyXxvBW6NiOciYi3wS+B/N11aK/I5Noh8jiXDNUCNAx4qTK+gxEE8kJR6lN6NdKVWJv0oSQuBR4GbIqJUvuzrwD8DLzdZTEgn6c8kLVDq8qaMicAq4MJc5fEdSRv3YdszgMtLFTJiJfBV4EHgYeCpiPhZye3cA7xb0laSXge8l/UfYLXm+Rwrz+dYHw3XANVSkjYBrgH+MSKeLpMnIl6KiCmkp/33lLRLyW29H3g0Ihb0sbjvioi3k3rLPl7S1BJ5RpOqaL4ZEbsBfwGaGjJF6aHT6cD3S6YfS7pCnwi8EdhY0sfK5I2Ie0k9fP8M+CmwEBiM54FsiPgc691wOMeGa4BqWRcvkjYgnTjfi4gfNJs/38bfQhoeoYx3AtMlLSdVs+wr6btNbG9l/vsocC3lerteAawoXIFeTTqZmnEwcHtE/Llk+v2BByJiVUS8CPwA+JuyG4uI8yNi94iYCqwm/XZhfedzrPz2fI710XANUC3pSkmSSHXG90bE15rI1yFpi/x+I+AA4L/L5I2IkyNi24iYQNrPX0REqaseSRtL2rT2HjiQdKve2zYfAR6S9OY8az9SbwXNOIKSVQ/Zg8Dekl6XP+f9SL8/lCJpm/x3PKlu/LImtm2v5nOs3HZ9jvVHf1tZVPVFqgP9A6ml0SlN5LucVP/6Iukq5pgm8r6LVN98F+kWdyHw3hL53gbckfPdA5zWx33ehyZaGJFaYN2ZX4ua/JymAF25zD8ExjaRd2NSZ6abN7l/nyN9qdwDXAqMaSLvr0kn+J3Afq0+PofDy+dYqfQ+x/rxcldHZmZWScO1is/MzNqcA5SZmVWSA5SZmVWSA5SZmVWSA5SZmVWSA1SbkfRS7qF4Ue6Z+VOSXpOXdUr6Rol1/C7/nSDpyMEus1k78TlWHW5m3mYkPRsRm+T325AehvttRJzeh3XtA3w6It4/sKU0a18+x6rDd1BtLFLXKbOA2Ur2UR6rJj85f1O+CvyOpD9K2jovq/Xq/CVSB48LlcaB2VlpzJyFku6SNKk1e2ZWDT7HWssBqs1FxDLSmC/b1C06ndQly86kfrzGN8h+EvDriJgSEWcDxwH/HqlDzU7SU/5mI5rPsdYZ3eoC2KB5F/BBgIj4qaTVJfL8HjhFaeybH0TE/YNZQLM253NskPkOqs1J2oHUrf2j/V1XRFxG6p7/eeB6Sfv2d51m7c7nWOs4QLUxSR3At4D/jFe3dvkt8OGc7kBgbINVPEMaNru2vh2AZRHxDeA6UgebZiOWz7HWchVf+9lIaVTQDYC1pB6HGw078DngcklHkaoVHiGdLEV3AS9JuhO4CBgDHCXpxZz+i4OyB2bV5nOsItzMfJiSNAZ4KSLWSnoHaWTOKa0ul9lw4XNs8PkOavgaD1yVHzB8ATi2xeUxG258jg0y30GZmVkluZGEmZlVkgOUmZlVkgOUmZlVkgOUmZlVkgOUmZlV0v8Hhyog7ycva64AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_dNMLRfuNk2"
      },
      "source": [
        "Remember, we want the lowest distance (either measured via Mean Absolute Difference, or RMSE) to be the one between our PNG and the digit's \"reference mean\" (i.e. the mean we calculated representing the average of all the training digits of that type). \n",
        "\n",
        "We can already see that for this particular 5 in our dataset, our distance measures are actually lower for other numbers (e.g. 3, 8). This isn't desired, but also isn't too surprising, as the handwritten digits are visually very similar. Let's see if this holds up on average for all the 5's, and whether our algorithm will perform better for other digits.\n",
        "\n",
        "We'll continue by loading all of our validation images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mFm4l1Xt0sx",
        "outputId": "3a3639ed-c544-4374-d336-ab5928ea21e9"
      },
      "source": [
        "validation_tensors = [\n",
        "      torch.stack([\n",
        "            tensor(Image.open(digit)).float()/255 for digit in testing[f'{num}']\n",
        "          ]) for num in range(10)\n",
        "      ]\n",
        "\n",
        "# Preview the shape of the stacked validation tensors of the \"zero\" digit\n",
        "validation_tensors[0].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([980, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BisGKMDivWH_"
      },
      "source": [
        "We need to write a function that takes each tensor stack in our `validation_tensors` list (one for each digit), and for each tensor in the stack measures the distance from the corresponding mean. \n",
        "\n",
        "Thanks to PyTorch's efficient use of broadcasting, we can feed in a stack as $a$ and a single tensor as $b$ (or viceversa) and PyTorch will automatically stack the single tensor multiple times to match the length of the stack. This allows the computation to be done using low-level C on the GPU (i.e. in parallel) and is several orders of magnitude faster than a regular Python `for` loop. Thankfully, our distance function doesn't need to change a whole lot, the only change being to add along which axes to calculate the mean in our tensor stack (see commented code below). We'll need another couple of functions to help us deal with multiple digits and multiple tensor stacks and aggregate all the scores.\n",
        "\n",
        "You can read the source code below, but here's a quick explanation: for each stack of tensors (e.g. tensors of all of the '3' images) in our validation set, we calculate the distance from each digit's reference mean and check that the lowest distance is that of the correct digit's reference mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dSL_yPUNL2V"
      },
      "source": [
        "def distance(a, b):\n",
        "  # Let's go with mean absolute error for now\n",
        "  return (a - b).abs().mean((-1,-2)) # the last two axes (e.g. 28x28)\n",
        "\n",
        "def is_correct(tensors, means, correct_index):\n",
        "  # make a list of the wrong digits' means indices\n",
        "  wrong_means = [i for i in range(10)]\n",
        "  wrong_means.pop(correct_index)\n",
        "\n",
        "  # calculate the distance from the correct reference mean\n",
        "  correct_distance = distance(tensors, means[correct_index])\n",
        "\n",
        "  # calculate and compare the distance to each wrong digit's reference mean\n",
        "  # and then checking that the distance is the lowest across all digits.\n",
        "  # each 'wdX' contains a tensor of Booleans -- eg tensor([True, False, ... ])\n",
        "  wd1 = correct_distance < distance(tensors, means[wrong_means[0]])\n",
        "  wd2 = correct_distance < distance(tensors, means[wrong_means[1]])\n",
        "  wd3 = correct_distance < distance(tensors, means[wrong_means[2]])\n",
        "  wd4 = correct_distance < distance(tensors, means[wrong_means[3]])\n",
        "  wd5 = correct_distance < distance(tensors, means[wrong_means[4]])\n",
        "  wd6 = correct_distance < distance(tensors, means[wrong_means[5]])\n",
        "  wd7 = correct_distance < distance(tensors, means[wrong_means[6]])\n",
        "  wd8 = correct_distance < distance(tensors, means[wrong_means[7]])\n",
        "  wd9 = correct_distance < distance(tensors, means[wrong_means[8]])\n",
        "  \n",
        "  # now we 'and' all the Boolean tensors together\n",
        "  wdf = torch.bitwise_and(wd1, \n",
        "                    torch.bitwise_and(wd2, \n",
        "                    torch.bitwise_and(wd3, \n",
        "                    torch.bitwise_and(wd4, \n",
        "                    torch.bitwise_and(wd5, \n",
        "                    torch.bitwise_and(wd6, \n",
        "                    torch.bitwise_and(wd7,\n",
        "                    torch.bitwise_and(wd8, wd9))))))))\n",
        "  \n",
        "  return  wdf.float().mean()\n",
        "\n",
        "def accuracy(stacks, means):\n",
        "  accuracy_map = [is_correct(stacks[i], means, i) for i in range(10)]\n",
        "  accuracy_tot = (sum(accuracy_map) / len(accuracy_map)).item()\n",
        "  return accuracy_tot, accuracy_map         "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "_S3OecMK3Y8g",
        "outputId": "78b28bfa-2d8a-4161-d953-da9109a53a4f"
      },
      "source": [
        "# Output our results!\n",
        "tot, map = accuracy(validation_tensors, training_means)\n",
        "print(\"Tot. Accuracy: {:.1%}\".format(tot))\n",
        "print(\"\\n\".join([\"Digit {} : {:.1%}\".format(i, map[i]) for i in range(10)]))\n",
        "\n",
        "# Plot results for a visual inspection\n",
        "plt.title(\"Baseline Performance Across Digits\")\n",
        "plt.axhline(tot, color='red', linewidth=2)\n",
        "plt.xticks(range(0, 10))\n",
        "plt.xlabel('Digits')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.bar(range(len(map)), map, align='center')    \n",
        "plt.plot(tot)\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tot. Accuracy: 66.1%\n",
            "Digit 0 : 81.5%\n",
            "Digit 1 : 99.8%\n",
            "Digit 2 : 42.3%\n",
            "Digit 3 : 60.9%\n",
            "Digit 4 : 66.8%\n",
            "Digit 5 : 32.6%\n",
            "Digit 6 : 78.7%\n",
            "Digit 7 : 76.5%\n",
            "Digit 8 : 44.3%\n",
            "Digit 9 : 77.6%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbCACCCPdKvU"
      },
      "source": [
        "It seems our simple mathematical comparison of average pixel values already achieves 66.1% overall accuracy across the validation set! This is impressive considering some digits have similar strokes (e.g. 3, 5 and 8). You can see from the bar chart above, some digits perform better than others, with the '1' digit recognition achieving near perfect accuracy (99.8%) in stark contrast to the '5' digit (32.6%). \n",
        "\n",
        "So we've covered terminology, we've established a simple baseline based on pixel arithmetic. Let's start building this darn deep neural network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx2pQqMzgN_5"
      },
      "source": [
        "## Thinking Like a Neural Network\n",
        "\n",
        "While \"Deep Learning\" sounds sophisticated, the underlying learning process under the hood doesn't sound quite as futuristic: \"try, rinse, repeat\". However, the real magic lies in the details, more specifically in how it \"rinses\" each cycle. After every cycle, it will adjust its own parameters to be \"better\". We'll see how it does this in just a second. Now let's reflect on our simple baseline method.\n",
        "\n",
        "Our baseline approach uses a very deterministic, binary algorithm for deciding whether a digit is correct or not: it will compare pixel distance with each reference mean and pick the mean where the distance is lowest. Considering that the input pixels and reference pixels never change, for each image our model will either be correct 100% of the time, or it will fail 100% of the time. There is no feedback loop, no way for the model to adjust along the way and no \"randomness\".\n",
        "\n",
        "Remember that our Linear Units have _parameters_. More specifically, each Linear Unit has a _weight_ and a _bias_: \n",
        "\n",
        "$y = \\textbf{w}x +\\textbf{b}$\n",
        "\n",
        "The beauty of parameters is that they can be tweaked, and the output $y$ will be different, much like we saw in our linear equation at the beginning of the post. \n",
        "\n",
        "With this simple equation as the engine for its neurons, a Neural Network is able to approximate anything. The approximation process is possible due to the iterative nature of trying a set of parameters, adjusting them and trying again. But how, you may be wondering, does a model choose the new set of parameters? Is it a random choice? Is it decided by a function? The answer is an inclusive \"yes\": it starts off with random values and gradually adjusts them according to a function: **the loss function**. The loss function measures how accurate the prediction is. The **optimizer function** then updates the parameters so as to minimize the loss function. It does this by looking at the rate of change (the gradient, aka slope) of each parameter as it was fed into the loss function and updates them (also called \"to step\") in the direction that will minimize the loss function. And this process has a fancy name, called **Stochastic Gradient Descent**. \n",
        "- _Descent_ because we want to get to make our way to the lower end of the loss function, \n",
        "- _Gradient_ because we use the gradient of each parameter to find in what direction to update them to make that descent, and \n",
        "- _Stochastic_ because it involves a litte bit of randomness, meaning it's not deterministic.\n",
        "\n",
        "Let's summarize all these steps again:\n",
        "1. We initialize the parameters (weights and biases for each input) to random values\n",
        "2. Make a prediction using those parameters\n",
        "3. Measure the accuracy of the prediction using a **loss function**\n",
        "4. We calculate how to update our parameters so as to minimize the loss function (remember: lower is better) using the **gradients** of the parameters' change as a result of the loss function. This is done via the **optimizer** function.\n",
        "5. We update our parameters and predict again, repeating the cycle until we are satisfied or the model stops improving significantly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "Ci58kzTY3z8p",
        "outputId": "b916aff7-2ccd-4dfc-a506-e88d6bda07c1"
      },
      "source": [
        "#hide_input\n",
        "gv('''\n",
        "initialize->predict->\"measure loss\"->\"step based on gradient\"->\"stop\"\n",
        "\"step based on gradient\"->predict[label=repeat]\n",
        "''')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fb5e9741a58>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"670pt\" height=\"83pt\"\n viewBox=\"0.00 0.00 670.16 83.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 79)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-79 666.1592,-79 666.1592,4 -4,4\"/>\n<!-- initialize -->\n<g id=\"node1\" class=\"node\">\n<title>initialize</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"42.2463\" cy=\"-18\" rx=\"42.4939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"42.2463\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">initialize</text>\n</g>\n<!-- predict -->\n<g id=\"node2\" class=\"node\">\n<title>predict</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"157.8893\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"157.8893\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n</g>\n<!-- initialize&#45;&gt;predict -->\n<g id=\"edge1\" class=\"edge\">\n<title>initialize&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M84.6508,-18C93.2685,-18 102.3792,-18 111.1378,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"111.2073,-21.5001 121.2073,-18 111.2072,-14.5001 111.2073,-21.5001\"/>\n</g>\n<!-- measure loss -->\n<g id=\"node3\" class=\"node\">\n<title>measure loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"289.1309\" cy=\"-57\" rx=\"57.6901\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"289.1309\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">measure loss</text>\n</g>\n<!-- predict&#45;&gt;measure loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>predict&#45;&gt;measure loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M189.3249,-27.3415C203.6432,-31.5963 220.9741,-36.7464 237.1485,-41.5528\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.4499,-44.9964 247.0326,-44.49 238.4439,-38.2864 236.4499,-44.9964\"/>\n</g>\n<!-- step based on gradient -->\n<g id=\"node4\" class=\"node\">\n<title>step based on gradient</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"477.5675\" cy=\"-18\" rx=\"93.6835\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"477.5675\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step based on gradient</text>\n</g>\n<!-- measure loss&#45;&gt;step based on gradient -->\n<g id=\"edge3\" class=\"edge\">\n<title>measure loss&#45;&gt;step based on gradient</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M337.658,-46.9565C357.7057,-42.8073 381.3951,-37.9044 403.5261,-33.3241\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.483,-36.7003 413.566,-31.2461 403.0642,-29.8456 404.483,-36.7003\"/>\n</g>\n<!-- step based on gradient&#45;&gt;predict -->\n<g id=\"edge5\" class=\"edge\">\n<title>step based on gradient&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M384.8792,-15.4434C338.7152,-14.5335 282.0534,-13.9629 231.286,-15 222.6715,-15.176 213.4918,-15.468 204.6452,-15.8026\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.3188,-12.3128 194.467,-16.2105 204.5992,-19.3072 204.3188,-12.3128\"/>\n<text text-anchor=\"middle\" x=\"289.1309\" y=\"-18.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n</g>\n<!-- stop -->\n<g id=\"node5\" class=\"node\">\n<title>stop</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"635.1592\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"635.1592\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n</g>\n<!-- step based on gradient&#45;&gt;stop -->\n<g id=\"edge4\" class=\"edge\">\n<title>step based on gradient&#45;&gt;stop</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M571.5148,-18C580.773,-18 589.7411,-18 597.8816,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"598.0612,-21.5001 608.0612,-18 598.0612,-14.5001 598.0612,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBjtMXZqOp4c"
      },
      "source": [
        "Let's begin by implementing _something_ that follows these rules. The reason I call it _something_ is that you'll see later why it's not exactly a Deep Neural Network. But it will help us learn along the way and take it step by step.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN1Gzo2LPtrM"
      },
      "source": [
        "## Primordial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2eue2YB3yb4"
      },
      "source": [
        "Our first Neural Network will start with a parameter for each pixel value of the input image ($28 \\times 28 = 784$), and will be fed directly into our loss function to measure our prediction accuracy. That means that our output needs to be a list of 10 probabilities--each probability corresponding to the likelihood that our reference image corresponds to a specific digit. These probabilities will need to sum to 1, as the classification is mutually exclusive (i.e. a '3' can only be a '3'). Other multi-label classification approaches are inclusive, meaning each input could have multiple labels (e.g. deciding if an image contains a person and/or a car and/or any other object). \n",
        "\n",
        "How do we condense all of our parameters into a list of probabilities? Say hello to my little friend: **Softmax**.\n",
        "\n",
        "### The Softmax Function\n",
        "\n",
        "The beautify of the Softmax function is that it normalizes a group of values from 0 to 1 in a way so that each value is interrelated with the others: together they sum to 1. This is perfect for generating a list of interrelated probabilities. If we were creating non-mutually exclusive classification, we would use Softmax's cousin Sigmoid, that normalizes each value from 0 to 1 _independently_. I'll leave diving deeper on the topic of Softmax vs Sigmoid as homework--you can start with this brilliant [blog post](https://glassboxmedicine.com/2019/05/26/classification-sigmoid-vs-softmax/).\n",
        "\n",
        "\n",
        "Let's admire Softmax in all of its glory:\n",
        "\n",
        "$\\text{Softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j{e^{x_j}}}$\n",
        "\n",
        "Don't worry, it's a lot simpler than it looks, and is even simpler once we code it.Here's a quick explanation of how our Softmax works in three steps:\n",
        "1. Given a list of values, we calculate the exponential for each value, that is: $e^{n}$. Where $n$ is our value and $e$ is Euler's number, a [special number in Mathematics](https://en.wikipedia.org/wiki/E_(mathematical_constant)), and at the heart of the exponential function.\n",
        "2. We sum the exponential values (the Sigma symbol $\\sum$ means _sum_).\n",
        "3. Take each value in Step 1. and divide it by the sum obtained in Step 2. \n",
        "\n",
        "As Jeremy Howard says: a mathematical concept often sounds complicated until you code it. So let's code it. Below is my quick softmax implementation:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZxqbpp7SMz4"
      },
      "source": [
        "# Quick softmax implementation, expecting a list of values (rank-1 tensor)\n",
        "def softmax(v):\n",
        "  \"\"\"\n",
        "  Given an input vector v, returns an output vector containing\n",
        "  the softmax values for each element in the vector\n",
        "  \"\"\"\n",
        "  exp_v = torch.exp(v.float())\n",
        "  exp_sum = exp_v.sum()\n",
        "  return exp_v / exp_sum"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alpyl-sY7SAv",
        "outputId": "fa720a5f-bc78-4158-953d-9d5a3d53cd94"
      },
      "source": [
        "# An softmax example with a list of values [1,2,3]\n",
        "softmax(tensor([1,2,3]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0900, 0.2447, 0.6652])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8DpHuuIZylH"
      },
      "source": [
        "### Datasets \n",
        "\n",
        "Now that we have Softmax in our toolbelt, we can move on with the implementation. Let's start by preparing our data. We'll take our tensor stacks. Let's reduce the dimensions of our data by transforming each image tensor from a matrix of 28x28 to a vector (a list) of size 28*28 (meaning each pixel is in a series, not in a 2D coordinate space)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEJCI1dy-16P"
      },
      "source": [
        "# Create a single list containing all the image tensors, as vectors\n",
        "train_x = torch.cat(training_tensors).view(-1, 28*28)\n",
        "valid_x = torch.cat(validation_tensors).view(-1, 28*28)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7GMulb9_EXx",
        "outputId": "80d71f37-f2eb-42a4-b908-304b5658b22b"
      },
      "source": [
        "train_x.shape, valid_x.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]), torch.Size([10000, 784]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_wtQncAZsku"
      },
      "source": [
        "As you can see from the output of `train_x.shape`, we went from a rank-3 tensor (60000, 28, 28) to a rank-2 tensor (60000, 784). We now want as many outputs from our model as number of labels (in our case digits). So we need to flag for each training image which is the correct digit. To do this we'll populate a tensor of length 10 as our corresponding target labels (also referred to as $y$ variables. In that case our inputs are usually referred to as $X$, representing our features) and add a \"1\" to flag the corresponding index in the tensor corresponding to our digit. You can see what it looks like for each digit below. \n",
        "\n",
        "Each row represents the correct label representation for each digit. For example, the first row is the output labels valid for _all_ the 'zero' tensors (index 0 is set to 1, and the rest are 0), the second being the output labels for _all_ the 'one' tensors (index 1 is set to 1 and the rest are 0), etc. In a way, the 1's location inside the indicates 100% probability that that index represents the correct digit. Ideally, we want our model to output the exact same output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7n7K4Ayrjj_",
        "outputId": "4740aab4-f6df-44d7-957f-aa431f4661a0"
      },
      "source": [
        "# Every digit's tensor stack will have a label\n",
        "# with the corresponding index flagged as '1'.\n",
        "\n",
        "[[0]*i + [1] + [0]*(9-i) for i in range(10)]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g19CvJt_SZ-"
      },
      "source": [
        "Let's associate a target label for each tensor in our stack, with the '1' corresponding to the digit it represents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQr0073d_FXO"
      },
      "source": [
        "# Label our training and validation sets with the index\n",
        "train_y = torch.from_numpy(np.concatenate([[[0]*i + [1] + [0]*(9-i)]*len(training[f'{i}']) for i in range(10)]))\n",
        "valid_y = torch.from_numpy(np.concatenate([[[0]*i + [1] + [0]*(9-i)]*len(testing[f'{i}']) for i in range(10)]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CwXlpSQ_kEK",
        "outputId": "0480b386-e0a0-459e-ec70-27c858fe0eb7"
      },
      "source": [
        "train_y.shape, valid_y.shape, train_y[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 10]),\n",
              " torch.Size([10000, 10]),\n",
              " tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8NSGgYy_cNk"
      },
      "source": [
        "Let's now merge them into a _dataset_. A dataset contains both $X$ and $y$ variables so that the model knows what $y$ to compare the prediction of $X$ against. We'll populate a training dataset with which to train the parameters, and a validation dataset that the parameters will never \"learn\" from, with which to benchmark our training against. A model may be very good at learning the peculiarities of its training data but may end up performing very poorly on its validation data as the features learned are not generalizable. This phenomenon is referred to as **over-fitting**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvGTC-AbCSZC",
        "outputId": "51638254-56d7-4944-bc27-d04979f19628"
      },
      "source": [
        "# Let's turn our training and validation X (features) and y (targets)\n",
        "# into datasets by zipping them so as to create a list of tuples (image tensor vector, label )\n",
        "dset = list(zip(train_x, train_y))\n",
        "dset_valid = list(zip(valid_x, valid_y))\n",
        "\n",
        "x,y = dset[0]\n",
        "x.shape,y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKIf8EAuLMmq"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI1GQvFXAT6l"
      },
      "source": [
        "What we'll do now is start defining functions that we'll end up merging into a single model class. The first function we'll need is a function that simply initiates random numbers, and these random numbers will be our weights and biases for each pixel.\n",
        "\n",
        "We'll use the `.requires_grad_()` in-place operation to ask PyTorch to track the gradients, as we'll need them later to backtrack and update our parameters according to the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y0zTAB2gi39"
      },
      "source": [
        "def init_params(sizeD1, sizeD2=0):\n",
        "  if sizeD2 == 0:\n",
        "    return (torch.randn(sizeD1)).requires_grad_()\n",
        "  else:\n",
        "    return (torch.randn(sizeD1, sizeD2)).requires_grad_()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpjyrifig5kd"
      },
      "source": [
        "weights = init_params(28*28, 10) # the 'w' of the linear equation\n",
        "bias = init_params(10) # the 'b' of the linear equation"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2j7d2J-zGyp",
        "outputId": "aa9d4d30-a3a0-46d0-abde-5e09ffeedaaf"
      },
      "source": [
        "weights.shape, bias.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 10]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J2TGyCxLV3Z"
      },
      "source": [
        "### Linear Equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaviLtDehxn8"
      },
      "source": [
        "Next we need a function that performs the famous Linear Unit (neuron) operation that we've been talking about since the beginning of the post. It's as simple as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIKFK8j_BOt6"
      },
      "source": [
        "def linear_eq(x):\n",
        "  return x@weights + bias"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG1xqs-OBPsw"
      },
      "source": [
        "Next we'll feed our training data `train_x` into our linear equation, which will associate the parameters we created earlier via matrix multiplication. That's what the `@` stands for in our function above. This gives us a first set of predictions (`preds`) that should perform quite poorly, more or less as well as picking the digits at random. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOdvriDghOGy",
        "outputId": "37def302-5bc3-4aa0-9d46-294392ad5f47"
      },
      "source": [
        "# Calculate predictions on all the tensors\n",
        "preds = linear_eq(train_x)\n",
        "preds"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-11.9867,  -4.2706,   4.6806,  ...,  -1.3517,  -0.0395,  13.5840],\n",
              "        [ -6.6797,  -4.4483,   1.4827,  ...,  -8.9409,   2.2570,  10.0881],\n",
              "        [-22.7994,   2.2295,  11.1160,  ...,  -1.8488,  25.5523,  22.3240],\n",
              "        ...,\n",
              "        [-16.7386,   4.0141,   3.9273,  ...,   1.5960,   9.7961,  12.3801],\n",
              "        [-14.1562,  -3.5679,   1.7541,  ...,   1.6506,  16.5308,  10.3213],\n",
              "        [-11.3688,   4.5965,   5.7170,  ...,  10.0353,   4.4967,   9.5438]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6LAgIAPhYsG",
        "outputId": "9f348273-6227-45e1-db32-3bbaf3dd8acc"
      },
      "source": [
        "# Check accuracy\n",
        "_, max_indices = preds.max(-1) # get the index of max value along 2nd dimension\n",
        "_, tag_indices = train_y.max(-1) # get index of flag in our label tensors\n",
        "\n",
        "corrects = max_indices == tag_indices # check whether they match\n",
        "corrects.float().mean() # calculate mean"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1204)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K5qy_aH2zQt"
      },
      "source": [
        "We see here that randomly initialized parameters will perform more or less like...well...a random choice. In our test above we got a 12% performance rate versus a random chance of 10% (choosing a random number from 1 to 10). This is expected and a good sense check that our model parameters are initialized randomly. Now comes the fun part. Let's create a loss function against which it can measure itself. After that, we'll see how can create an optimizer function that will decide how to update the parameters to minimize the loss function, so as to continuously improve cycle after cycle.\n",
        "\n",
        "We'll first softmax our parameters so that they are between 0 and 1, and we'll check whether the outputs match the targets. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzgp8Qtd09fd"
      },
      "source": [
        "# We'll use PyTorch's built in softmax function \n",
        "# so we can work in multiple dimensions easily.\n",
        "# It works exactly like our own softmax()\n",
        "def loss_function(predictions, targets):\n",
        "  sm = nn.Softmax(dim=-1) # instantiate PyTorch's softmax in the 2nd dimension\n",
        "  predictions = sm(predictions) # calculate the softmax across the 2nd dimension\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean(-1)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-wXp0QYAfr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d441ff31-13ca-4495-fabf-849f7df29630"
      },
      "source": [
        "loss_function(preds, train_y)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.2000, 0.2000,  ..., 0.0141, 0.1996, 0.1299], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR3Kiv_CDky1"
      },
      "source": [
        "### The Optimizer\n",
        "\n",
        "Once our model instantiates random parameter values, makes a prediction and measures the first prediction against the loss function, we now have \"report card\" for how it performed. Staying with that analogy, now is the time to read our report card (our \"grades\" are the distances from the target value) and fix our parameters so we get a better grade the next time around, using the teacher's feedback (our gradients).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8tpjNUQEmys"
      },
      "source": [
        "We first need to get our gradients, and then update our parameters using a simple formula in Stochastic Gradient Descent. This is what the formula looks like for each parameter $w$:\n",
        "\n",
        "$ w := w - \\eta \\nabla Q({w}) $\n",
        "\n",
        "As usual, this looks super complicated until you see it in code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgiJCmhREpQN"
      },
      "source": [
        "# Compute the loss\n",
        "loss = loss_function(preds, yb)\n",
        "\n",
        "# Get the gradients\n",
        "loss.mean().backward()\n",
        "\n",
        "# Optimize our parameters\n",
        "for p in [weights, bias]:\n",
        "    p.data -= p.grad*lr # this line is the formula above\n",
        "    p.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFpcsetGnai"
      },
      "source": [
        "All we're doing is just subtracting the gradient! To get the gradient, `p.grad`, we need to use PyTorch's `.backward()` functionality on the output of our `loss_function`, $Q$, so it can calculate the gradients for all the parameters in our weight and bias tensors as a result of the loss function. This is done automatically thanks to the fact that we added `.requires_grad_()` earlier to our parameters.\n",
        "\n",
        "If you have a keen eye, you'll see in the code that we muliply the `p.grad` by a value called `lr`. This is the **learning rate**, $\\eta$ in the formula. This is just a weighing factor we use to reduce the amount of movement along the loss function from one update to the next. Typical values range from 0.001 to 0.1. Why is it important to not go too much in one direction? If you imagine a loss function like a parabola, our optimal point is at the bottom of the parabola. If we overshoot, we could be bouncing around from one side of the parabola to the other. A smaller step-based approach helps prevent that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcm32XgYK_JI"
      },
      "source": [
        "### Batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vupJ_NWnEtNb"
      },
      "source": [
        "Before we combine everything together into a model, let's introduce the concept of **batches**. Rather than measure predictions across all the dataset before estimating our performance, research has found that doing it with batches of training data is significantly faster and yields good results. This is also referred to as _mini-batches_. It's a compromise between having to run your function against _all_ the values in the training dataset every time (therefore requiring a lot of resources when you have millions of items to process), or doing it for each single item in the dataset, which would be fast, but would not be representative of the group. Either extremes are bad for different reasons, so a good compromise is selecting a random batch of samples every time, and running the prediction-loss-step cycle on that batch thereby updating the parameters. A good batch size is small enough to be performant and large enough to be somewhat representative of the overall dataset. When we complete a round of batches (i.e. all of our samples are used in training exactly once), we have completed an **epoch**. \n",
        "\n",
        "For batching, we'll use fast.ai's DataLoader. While it offers a lot of additional functionality, all we'll use it for is as an iterator that will split up our inputs into batches to feed into the model until all the samples are fed through. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seaLcowimGcR"
      },
      "source": [
        "dl = DataLoader(dset, batch_size=128, shuffle=True)\n",
        "valid_dl = DataLoader(dset_valid, batch_size=128, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D17mPc6bLdXz"
      },
      "source": [
        "### Our MNIST Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOWT7tGhIuVf"
      },
      "source": [
        "Now that our dataset is conveniently split up into batches, we can combine all the different functionality we saw up until now and create an MNIST Model class to train. Below is a (naive and specific) implementation of a Model specifically trained to deal with the characteristics of our MNIST task.\n",
        "\n",
        "Our class has the following characteristics (feel free to skip ahead and just read the source code directly)\n",
        "\n",
        "#### Inputs\n",
        "\n",
        "This is what the model needs to instantiate:\n",
        "- `train_dl`: our training DataLoader\n",
        "- `valid_dl`: our validation DataLoader\n",
        "- `epochs`: the number of epochs (complete rounds of the training data to perform)\n",
        "- `lr`: our learning rate\n",
        "- `verbose`: which just flags whether we want to print out feedback.\n",
        "\n",
        "#### Functions\n",
        "\n",
        "These are the functions our model uses to perform the operations. They are prefixed with an `_` to differentiate them from our methods.\n",
        "- `_print()`: is just a simple print function that only prints if flag `verbose` is true.\n",
        "- `_init_params()`: our initializes parameters.\n",
        "- `_linear_eq()`: our linear equation above.\n",
        "- `_loss_function()`: our loss function above.\n",
        "- `_calc_grad()`: takes the input training data, runs it through `_linear_eq` to get predictions and calculates the loss via the `_loss_function`. Then calls `.backwards()` on the loss results to get the gradients.\n",
        "- `_batch_accuracy()`: softmaxes a prediction and compares it against the corresponding label. That is, the index with the max value in the vector (highest probability) should be the same as the index with the '1' flag in our label vector. True if it's the case, False otherwise. Then returns the mean result, representing our batch accuracy. This is used in our `_validate_epoch` function and only used with validation data.\n",
        "- `_validate_epoch()`: once a training epoch is complete, we run our model through each batch of our validation data and cumulatively aggregate accuracies of each batch obtained via `_batch_accuracy` into an overall epoch score.\n",
        "\n",
        "#### Methods\n",
        "\n",
        "Our model has two main methods: `train` and `predict`. \n",
        "- `train`: for each epoch, for each batch performs the training (via `_calc_grad`), the optimizing and validates each epoch (via `_validate_epoch`). \n",
        "- `predict`: similar to _batch_accuracy but only works on a single input image. It expects an image tensor as input and runs the tensor through its current parameters, outputting its predicted digit as well as the probabilities for other digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqg5hImga71j"
      },
      "source": [
        "#collapse_show\n",
        "class MNISTLinearRegression:\n",
        "  def __init__(self, train_dl, valid_dl, epochs, lr, verbose):\n",
        "    self.lr = lr\n",
        "    self.train_dl = train_dl\n",
        "    self.valid_dl = valid_dl\n",
        "    self.epochs = epochs\n",
        "    self.weights, self.bias = self._init_params()\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "    self.accuracy_scores = []\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def train(self):\n",
        "    for i in range(self.epochs):\n",
        "      for xb, yb in self.train_dl:\n",
        "        self._calc_grad(xb, yb)\n",
        "        for p in [self.weights, self.bias]:\n",
        "            p.data -= p.grad*self.lr\n",
        "            p.grad.zero_()\n",
        "\n",
        "      self._validate_epoch(i)\n",
        "\n",
        "  def predict(self, image_tensor):\n",
        "    probabilities = self.softmax(self._linear_eq(image_tensor))\n",
        "    _, prediction = probabilities.max(-1)\n",
        "    #self._print(\"Predicted digit: {} (with {:.2%} confidence)\".format(1,0.9))\n",
        "    # Return digit and vector of probabilities\n",
        "    return prediction, probabilities\n",
        "\n",
        "  def _calc_grad(self, xb, yb):\n",
        "    preds = self._linear_eq(xb)\n",
        "    loss = self._loss_function(preds, yb)\n",
        "    loss.mean().backward()\n",
        "\n",
        "  def _batch_accuracy(self, xb, yb):\n",
        "    predictions = self.softmax(xb) # calculate the softmax across the 2nd dimension\n",
        "    _, max_indices = xb.max(-1) # get the index of max value along 2nd dimension\n",
        "    _, tag_indices = yb.max(-1) # get index of flag in our label tensors\n",
        "    corrects = max_indices == tag_indices # check whether they match\n",
        "    return corrects.float().mean() # calculate mean\n",
        "\n",
        "  def _validate_epoch(self, i):\n",
        "    accs = [self._batch_accuracy(self._linear_eq(xb), yb) for xb,yb in self.valid_dl]\n",
        "    score = round(torch.stack(accs).mean().item(), 4)\n",
        "    self.accuracy_scores.append(score)\n",
        "    self._print(f'Epoch #{i}', score)\n",
        "\n",
        "  def _linear_eq(self, x):\n",
        "    return x@self.weights + self.bias\n",
        "\n",
        "  def _loss_function(self, predictions, targets):\n",
        "    predictions = self.softmax(predictions) # calculate the softmax across the 2nd dimension\n",
        "    return torch.where(targets==1, 1-predictions, predictions).mean(-1)\n",
        "\n",
        "  def _print(self, *args):\n",
        "    if self.verbose:\n",
        "      print(*args)\n",
        "\n",
        "  # Linear regression using SGD\n",
        "  def _init_params(*args):\n",
        "    return (torch.randn(28*28, 10)).requires_grad_(), (torch.randn(10)).requires_grad_()\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGIUdcMHPxqE"
      },
      "source": [
        "Now that we've created it, let's try it in action!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wvrk9NJIqD8"
      },
      "source": [
        "model = MNISTLinearRegression(dl, valid_dl, 50, 1, True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VARTm-4Amb2Y",
        "outputId": "97266aa4-5c0b-4321-c419-f89625eb724c"
      },
      "source": [
        "model.train()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0 0.225\n",
            "Epoch #1 0.2896\n",
            "Epoch #2 0.335\n",
            "Epoch #3 0.3665\n",
            "Epoch #4 0.4239\n",
            "Epoch #5 0.4645\n",
            "Epoch #6 0.486\n",
            "Epoch #7 0.5055\n",
            "Epoch #8 0.5214\n",
            "Epoch #9 0.5243\n",
            "Epoch #10 0.5343\n",
            "Epoch #11 0.5356\n",
            "Epoch #12 0.5389\n",
            "Epoch #13 0.5466\n",
            "Epoch #14 0.5463\n",
            "Epoch #15 0.5468\n",
            "Epoch #16 0.5506\n",
            "Epoch #17 0.5522\n",
            "Epoch #18 0.553\n",
            "Epoch #19 0.5556\n",
            "Epoch #20 0.5578\n",
            "Epoch #21 0.5579\n",
            "Epoch #22 0.5573\n",
            "Epoch #23 0.5617\n",
            "Epoch #24 0.5599\n",
            "Epoch #25 0.5615\n",
            "Epoch #26 0.5599\n",
            "Epoch #27 0.5615\n",
            "Epoch #28 0.5604\n",
            "Epoch #29 0.5602\n",
            "Epoch #30 0.5666\n",
            "Epoch #31 0.5702\n",
            "Epoch #32 0.5837\n",
            "Epoch #33 0.6356\n",
            "Epoch #34 0.6464\n",
            "Epoch #35 0.6619\n",
            "Epoch #36 0.677\n",
            "Epoch #37 0.6907\n",
            "Epoch #38 0.6961\n",
            "Epoch #39 0.7083\n",
            "Epoch #40 0.7107\n",
            "Epoch #41 0.7188\n",
            "Epoch #42 0.7252\n",
            "Epoch #43 0.7276\n",
            "Epoch #44 0.7353\n",
            "Epoch #45 0.7479\n",
            "Epoch #46 0.7646\n",
            "Epoch #47 0.7808\n",
            "Epoch #48 0.7929\n",
            "Epoch #49 0.8005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG6Dyf_HkpJR"
      },
      "source": [
        "Not bad! After 50 epochs we reached 80% accuracy, way ahead of our baseline! I tried running this multiple times and the results vary, depending on the initial parameters and the learning rate.\n",
        "\n",
        "Remember the example '5' we used earlier in the post to try out our baseline average pixel value approach? If you remember, it didn't even work properly as the distance to the reference means '3' and '8' was closer! Let's take that same image and see what our model predicts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lQvQA8Gjzxg",
        "outputId": "a1c22abc-967f-4f85-ffe3-900c1843ca4a"
      },
      "source": [
        "val_5 = (tensor(Image.open(testing['5'][0])).float()/255).view(-1, 28*28)\n",
        "a = model.predict(val_5)\n",
        "a"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5]),\n",
              " tensor([[1.6423e-13, 7.6946e-22, 1.9228e-15, 2.0405e-04, 1.1598e-18, 9.9980e-01, 6.9507e-23, 2.2210e-20, 5.8148e-25, 1.8752e-18]], grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOQ2JNyFP5Kz"
      },
      "source": [
        "Yay. It works! It correctly predicted the '5' digit, with probability 99.98%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_GB56zgJvF0"
      },
      "source": [
        "## Activating our network!\n",
        "\n",
        "You may have noticed that we called our model a \"MNISTLinearRegressor\". I have to break it to you, what we've done up to now is create a linear regressor with a self-correcting capability through Stochastic Gradient Descent..._not_ a neural network. That being said, we've gotten some pretty impressive results with just this linear classifier. However, a neural network is non-linear. How do we break the linearity? That is what we'll tack in **Part 2** (to be published soon)!"
      ]
    }
  ]
}